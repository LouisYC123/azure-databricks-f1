{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48300110-9e91-430c-b0e9-aa4d4e14f12c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Ingest pitsops.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd81255-37f3-414a-98e7-822ed9d4cd4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# When you're processing a multi-line JSON, you need to explicitly tell Spark that it is a multi-line JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95af95d4-8b74-425e-9b89-018cca060812",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import current_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfbb1084-2594-4264-aeb7-2eb624f6b058",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1 - Read the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b11f29e2-b6a0-47f9-a379-71b9063bea49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pitstops_schema = StructType(fields=[\n",
    "    StructField(\"raceId\", IntegerType(), False ),\n",
    "    StructField(\"driverId\", IntegerType(), True ),\n",
    "    StructField(\"stop\", StringType(), True ),\n",
    "    StructField(\"lap\", IntegerType(), True ),\n",
    "    StructField(\"time\", StringType(), True ),\n",
    "    StructField(\"duration\", StringType(), True ),\n",
    "    StructField(\"milliseconds\", IntegerType(), True ),\n",
    "])\n",
    "\n",
    "pitstops_df = spark.read.schema(pitstops_schema).option(\"multiline\", True).json(\"/mnt/formula1lgdl/raw/pit_stops.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c584c12-77f7-4175-9fed-f8bfc32d9501",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2 - Rename columnss and add new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5987e091-9ba4-4325-bbe2-2a3f22100f64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df = pitstops_df.withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    ".withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    ".withColumn(\"ingestion_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ef374f4-2895-48ea-8969-c22a446f939d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3 - Write to output to processes container in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff819265-adbd-414e-a741-c6377b087324",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df.write.mode(\"overwrite\").parquet(\"/mnt/formula1lgdl/processed/pit_stops\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_pitstops_file",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
